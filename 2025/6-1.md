# 📚 - 주차

### 주제 1: Spurious Rewards: Rethinking Training Signals in RLVR
- **발표자**: 박민경

### 리뷰 1
- **리뷰어**: 
(내용)

---

### 리뷰 2
- **리뷰어**: 
(내용)

---

<br>

### 주제 2: Absolute Zero: Reinforced Self-play Reasoning with Zero Data
- **발표자**: 조재현

### 리뷰 1
- **리뷰어**: 박민경

1. 문제의식

추론/코딩 모델은 사람이 생성한 데이터셋에 기반해 학습된다. 하지만 인간이 설계한 문제는 비용이 높고 편향될 수도 있으며 범위가 제한적. 또한 모델은 주어진 데이터셋을 과적합하게 되고 일반적인 추론 능력을 키우기가 어렵다. 또한 인간이 만든 데이터셋으로는 모델 성능의 고점이 정해진다는 한계가 존재한다.

2. Absolute Zero

이 발표에서는 모델이 스스로 문제를 만들고 푸는 방식으로 추론 능력을 강화하는 'self-play reasoning' 기법을 소개한다. 랜덤 씨드로써 가장 최초의 아주 간단한 문제 1개는 필요하지만 그 외에 외부 문제 데이터나 사람의 피드백이 전혀 필요하지 않고 보상도 코드 실행 결과로 RLVR을 통해 줄 수 있다. 

3. 문제 생성

문제를 만들 때 program-input을 주고 Output을 생성, program-output을 주고 Input을 생성, input-output을 주고 Program을 생성하는 3가지 구조로 나눴다. 이 구조를 바탕으로 모델은 논리적으로 타당한 문제 구조를 학습할 수 있고 점점 복잡한 문제를 생성할 수 있게 되는 것 같다.

4. 리뷰

학습 데이터셋이 없어도 Absolute zero 방식은 수학, 코딩 문제 해결 능력에서 강력한 성능향상이 있었다. 이는 사람이 데이터셋을 생성하는 기존 방법론의 한계를 극복할 수 있게 한다. Absolute zero은 문제 생성자와 해결자 역할을 동시에 수행하면서 문제를 잘 만드는 것이 곧 추론 능력을 학습하는 핵심이 될 수 있다는 점을 실험적으로 보였다. 인간의 개입이 없는 스스로 사고하는 인공지능을 위한 중요한 연구 내용이 될 것 같다.

---

### 리뷰 2
- **리뷰어**: 
(내용)

---

<br>

### 주제 3: Calm-Whisper: Reduce Whisper Hallucination On Non-Speech By Calming Crazy Heads Down
- **발표자**: 장재후

### 리뷰 1
- **리뷰어**: 박민경

1. 문제 정의

위스퍼는 뛰어는 음성인식 성능을 보이는 모델이지만 노이즈(배경음, 소음)등에 대해 실제 존재하지 않는 문장을 생성하는 hallucination문제가 있다. 특히 whisper는 autoregressive decoder 구조를 가지고 있기 때문에 인코더만을 사용하는 CTC계열 모델 대비 hallucination문제에 훨씬 취약하다고 볼 수 있다.

2. 해결 방법

이 세미나의 발표 내용에서는 whisper의 hallucination문제가 디코더의 self-attention 헤드에 의거한 것이라고 보고 이에 대한 영향을 분석했다. 그리고 몇 개의 헤드에서 전체 hallucination현상의 대부분을 유발하는 현상을 관찰했다. 이에 착안하여 식별된 몇 개의 문제 헤드만을 노이즈 데이터셋으로 따로 파인튜닝하여 hallucination을 줄이는 방법을 제안하였다.

3. 리뷰

풀 파인튜닝 혹은 몇 개의 헤드만 파인튜닝 하는 경우에도 hallucination현상이 줄어들면 WER이 증가하는 trade-off 결과를 관찰할 수 있었다. 그래도 여기서 주장한 Calm-down 기법은 hallucination를 크게 감소시키면서 WER이 조금 상승하는 결과를 보여주어 성능 저하 없이 hallucination문제를 효과적으로 완화하였다고 한다. 위스퍼의 Seq2Seq 구조에서 오는 이러한 문제점들을 분석하여 해결하는 연구들이 앞으로 더 기대가 된다.

---

### 리뷰 2
- **리뷰어**: 
(내용)

---