# 📚 5 - 2 주차

### 주제 1: Atom of Thoughts for Markov LLM Test-Time Scaling
- **발표자**: 장재후

### 리뷰 1
- **리뷰어**: 박민경

#### 개요 및 정리
주제 1에 대한 발표는 복잡한 추론 작업에서 연속 프롬프팅과 CoT방식의 한계를 극복하기 위한 새로운 접근 방식으로서, Markovian Process 기반의 AoT추론 구조를 제안 논문에 대한 내용이었다. 기존 reasoning 방식에서 발생하는 context contamination 문제를 지적하며 이를 해결하기 위한 구조화된 문제 분해 방식에 대해 소개했다.

내가 생각했을 때 CoT와 AoT의 주요 차이는 
- CoT : 하나의 큰 질문을 그대로 입력하여 여러개의 reasoning을 도출하여 하나의 답을 낸다.
- AoT : 하나의 큰 질문을 여러 개의 하위 질문으로 나누고, 각각에 대해 독립적인 reasoning과 답변을 낸다.

하위 질문 생성은 LLM기반으로 생성하고, 결과를 DAG(Directed Acyclic Graph)를 기반으로 질문간 의존성 구조를 모델링한다고 한다. 하위 질문 분해는 LLM 자체가 생성하는 데 여기서 LLM이 질문을 효과적으로 분해할 수 있다면 그 자체로 복잡한 reasoning 능력을 보유한 것인가? 하는 생각이 들었다. 하지만 실험 결과에서 대형 모델을 이용해 CoT한 결과보다 소형 모델로 AoT한 방식이 훨씬 좋은 성능결과를 보였다. 이는 이와 아래와 같은 시사점을 제공한다.
- 컴퓨팅 자원이 제한된 환경에서 AoT는 매우 효과적인 방식이 될 수 있다.
- 단순하면서도 직관적인 아이디어가 구조적 reasoning 문제에 실질적인 대안을 제시할 수 있다.
- MP 기반으로 문제를 구조화함으로써, reasoning의 실용성과 확장성이 확보된다.

#### 후기
이 논문은 LLM 기반 추론의 실질적 한계를 날카롭게 짚고, 이를 극복하기 위한 창의적이고도 실용적인 해법을 제시했다. 특히 MP를 reasoning 구조에 도입해 context 오염 문제를 해결하려는 시도는 인상 깊었다. 질문 분해를 통한 구조화와 효율성 개선이라는 측면에서 AoT 방식은 향후 다양한 복잡한 reasoning task에 응용 가능성이 크며, 리소스가 제한된 실제 환경에서도 활용 가능한 솔루션으로 주목할 만하다.

---

### 리뷰 2
- **리뷰어**: 조재현
### 후기
큰 문제를 작은 문제로 변환하는 방식은, 실제 사람이 수학 문제를 푸는 방식과 유사하다. 합리적인 motivation과 method를 갖고 있는 방식으로, 좋은 성능을 얻었다. detail하게는, 문제의 정보를 graph화 하여, 정보 사이의 관계를 도출하고, 당장 해결할 수 있는 작은 문제를 푸는 방식이 인상적이었다.

---

<br>

### 주제 2: Multi-stage Instruction Prompt Optimization
- **발표자**: 박민경

### 리뷰 1
- **리뷰어**: 장재후

### 요약
```
MIPRO(Muti-prompt Instruction PRoposal Optimizer) 프레임워크에 대한 전반적인 아키텍쳐, 구성요소, 사용법들을 소개하였음. 
MIPRO 프레임워크의 경우, 일반적인 LM 최적화 프로그램의 순서를 따르며 베이지안 최적화를 사용해서 optimization을 진행함. 
bootstrapping demonstration, grounding, learning to propose 과정을 거쳐서 최적 하이퍼파라메터를 결정함.
하이퍼파라메터를 업데이트하면서 이와 동시에 각 케이스 별 프롬프트에 대한 성능을 측정함. 최종적으로 임계값을 넘는 고품질 프롬프트 샘플들을 확보해서 이를 출력하는 프레임워크임
```

### 후기
```
회사에서 실제로 매 개발시마다 정성적인 평가를 통해 직접 프롬프트를 작성해왔는데 이 과정이 너무 오래걸리고 힘들었음.
사내 프로덕트에 도입하는 프롬프트를 만들때 MIPRO 프레임워크를 적용하는 것도 좋을 것 같음.
기본적인 조건 제시만으로 편하게 최적화된 프롬프트를 생성할 수 있을 것으로 보임.
```
---

### 리뷰 2
- **리뷰어**: 조재현
### 후기
Prompt optimization framework를 소개하였다. 개인적으로는 직접 결과를 확인해가며, 무식한 방식으로 prompt engineering을 해왔는데, 이런 방식을 이용하면 합리적인 방식으로 최적화 할 수 있을 것 같다. 특히, 현업에서는 이런 쪽의 니즈가 강한 것을 알게 되었다.


---

<br>

### 주제 3: KNOWLEDGE ENTROPY DECAY DURING LANGUAGE MODEL  PRETRAINING HINDERS NEW KNOWLEDGE ACQUISITION
- **발표자**: 조재현

### 리뷰 1
- **리뷰어**: 박민경

#### 개요 및 정리
재현씨는 저번 주에는 Test-time leverage에 관한 논문을 발표하셨는데, 이번 주에는 pretraining 최적화에 관한 논문을 발표해주셨다. 전반적인 내용은 LLM의 Pretraining 과정에서 발생하는 Knowledge entropy 감소 현상이 모델의 새로운 지식 습득 능력에 미치는 영향을 분석하고 해결 방안을 제시하였다.

- knowledge entropy
논문에서 제안하는 knowledge entropy는 모델이 다양한 메모리 소스를 활용하는 정도를 정량화하는 지표이다. knowledge entropy가 낮다면 모델이 특정 소스에서만 의존함을 의미한다.모델의 FFN구조에서 입력 x에 대해 $ffn(x)=f(x\cdot K^T)V$로 표현되고 학습이 진행될수록 V가 특정 메모리 벡터에 의존하게 되어, 메모리 벡터의 활성화가 sparse해지는 경향이 나타났다.

이를 해결하기 위해 논문에서는 잘 사용되지 않는 메모리 벡터를 활성화시키는 booster 메커니즘을 제안했다. 이는 dropout과 유사하지만 특정 비활성화된 메모리 벡터를 선택적으로 강화해 knowledge entropy 감소를 완화하고자 했다.

#### 후기
논문에서 제안한 booster 메커니즘은 직관적인 아이디어지만 기존의 과적합 방지 기법들 (weight decay, warmup, lora, MoFO, GEM)과 비교했을 때 효과성이나 실용성 측면에서 구체적인 비교 분석이 필요해 보인다. 특히 일부 실험에서는 이 메커니즘의 성능이 입증되지 않는 결과가 나타나기도 하였다. LLM의 학습 효율성과 일반화 능력을 향상시키기 위해 중요한 시사점은 제공했으나 향후 이를 해결하기 위한 전략에 대한 연구로 확장이 필요해보인다.

---

### 리뷰 2
- **리뷰어**: 장재후
  
### 요약
```
LLM pretrain 중 knowledge entropy가 지속적으로 감소함을 발견했음.
감소하는 knowledge entropy는 모델이 새로운 지식을 획득하고 기존 지식을 유지하는 능력을 저해하는 것과 강한 상관관계가 있는 것을 밝혀냄.
이는 pretraining 중간 단계 모델이 추가 fine-tuning을 위한 시작점으로 적합할 수 있음을 시사함.
```

### 후기
```
이 논문이 제시하는 엔트로피 감소 현상은 이러한 continual learning이 왜 어려운지에 대한 이론적 근거가 될 수 있음.
또한, 사전 학습 후반부에 모델이 새로운 지식을 잘 학습하지 못하는 현상을 설명하려는 시도가 매우 흥미롭게 느껴졌음.
해당 논문은 앞으로 새로운 지식을 LLM에 추가로 입히는 과정을 좀더 최적화하여 탐색하기 위한 참고 지식으로 중요하게 사용 될 것으로 보임
```

---
