# 📚 - 주차

### 주제 1: Atom of Thoughts for Markov LLM Test-Time Scaling
- **발표자**: 장재후

### 리뷰 1
- **리뷰어**: 박민경

#### 개요 및 정리
주제 1에 대한 발표는 복잡한 추론 작업에서 연속 프롬프팅과 CoT방식의 한계를 극복하기 위한 새로운 접근 방식으로서, Markovian Process 기반의 AoT추론 구조를 제안 논문에 대한 내용이었다. 기존 reasoning 방식에서 발생하는 context contamination 문제를 지적하며 이를 해결하기 위한 구조화된 문제 분해 방식에 대해 소개했다.

내가 생각했을 때 CoT와 AoT의 주요 차이는 
- CoT : 하나의 큰 질문을 그대로 입력하여 여러개의 reasoning을 도출하여 하나의 답을 낸다.
- AoT : 하나의 큰 질문을 여러 개의 하위 질문으로 나누고, 각각에 대해 독립적인 reasoning과 답변을 낸다.

하위 질문 생성은 LLM기반으로 생성하고, 결과를 DAG(Directed Acyclic Graph)를 기반으로 질문간 의존성 구조를 모델링한다고 한다. 하위 질문 분해는 LLM 자체가 생성하는 데 여기서 LLM이 질문을 효과적으로 분해할 수 있다면 그 자체로 복잡한 reasoning 능력을 보유한 것인가? 하는 생각이 들었다. 하지만 실험 결과에서 대형 모델을 이용해 CoT한 결과보다 소형 모델로 AoT한 방식이 훨씬 좋은 성능결과를 보였다. 이는 이와 아래와 같은 시사점을 제공한다.
- 컴퓨팅 자원이 제한된 환경에서 AoT는 매우 효과적인 방식이 될 수 있다.
- 단순하면서도 직관적인 아이디어가 구조적 reasoning 문제에 실질적인 대안을 제시할 수 있다.
- MP 기반으로 문제를 구조화함으로써, reasoning의 실용성과 확장성이 확보된다.

#### 후기
이 논문은 LLM 기반 추론의 실질적 한계를 날카롭게 짚고, 이를 극복하기 위한 창의적이고도 실용적인 해법을 제시했다. 특히 MP를 reasoning 구조에 도입해 context 오염 문제를 해결하려는 시도는 인상 깊었다. 질문 분해를 통한 구조화와 효율성 개선이라는 측면에서 AoT 방식은 향후 다양한 복잡한 reasoning task에 응용 가능성이 크며, 리소스가 제한된 실제 환경에서도 활용 가능한 솔루션으로 주목할 만하다.

---

### 리뷰 2
- **리뷰어**: 
(내용)

---

<br>

### 주제 2: Multi-stage Instruction Prompt Optimization
- **발표자**: 박민경

### 리뷰 1
- **리뷰어**: 장재후

### 요약
```
MIPRO(Muti-prompt Instruction PRoposal Optimizer) 프레임워크에 대한 전반적인 아키텍쳐, 구성요소, 사용법들을 소개하였음. MIPRO 프레임워크의 경우, 일반적인 LM 최적화 프로그램의 순서를 따르며 베이지안 최적화를 사용해서 optimization을 진행함. bootstrapping demonstration, grounding, learning to propose 과정을 거쳐서 prompt를 업데이트함.
```

### 후기
```
(작성중)
```
---

### 리뷰 2
- **리뷰어**: 
(내용)

---

<br>

### 주제 3: KNOWLEDGE ENTROPY DECAY DURING LANGUAGE MODEL  PRETRAINING HINDERS NEW KNOWLEDGE ACQUISITION
- **발표자**: 조재현

### 리뷰 1
- **리뷰어**: 박민경

#### 개요 및 정리
재현씨는 저번 주에는 Test-time leverage에 관한 논문을 발표하셨는데, 이번 주에는 pretraining 최적화에 관한 논문을 발표해주셨다. 전반적인 내용은 LLM의 Pretraining 과정에서 발생하는 Knowledge entropy 감소 현상이 모델의 새로운 지식 습득 능력에 미치는 영향을 분석하고 해결 방안을 제시하였다.

- knowledge entropy
논문에서 제안하는 knowledge entropy는 모델이 다양한 메모리 소스를 활용하는 정도를 정량화하는 지표이다. knowledge entropy가 낮다면 모델이 특정 소스에서만 의존함을 의미한다.모델의 FFN구조에서 입력 x에 대해 $ffn(x)=f(x\cdot K^T)V$로 표현되고 학습이 진행될수록 V가 특정 메모리 벡터에 의존하게 되어, 메모리 벡터의 활성화가 sparse해지는 경향이 나타났다.

이를 해결하기 위해 논문에서는 잘 사용되지 않는 메모리 벡터를 활성화시키는 booster 메커니즘을 제안했다. 이는 dropout과 유사하지만 특정 비활성화된 메모리 벡터를 선택적으로 강화해 knowledge entropy 감소를 완화하고자 했다.

#### 후기
논문에서 제안한 booster 메커니즘은 직관적인 아이디어지만 기존의 과적합 방지 기법들 (weight decay, warmup, lora, MoFO, GEM)과 비교했을 때 효과성이나 실용성 측면에서 구체적인 비교 분석이 필요해 보인다. 특히 일부 실험에서는 이 메커니즘의 성능이 입증되지 않는 결과가 나타나기도 하였다. LLM의 학습 효율성과 일반화 능력을 향상시키기 위해 중요한 시사점은 제공했으나 향후 이를 해결하기 위한 전략에 대한 연구로 확장이 필요해보인다.

---

### 리뷰 2
- **리뷰어**: 
(내용)

---
