# 📚 8 - 1 주차

### 주제 1 : Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection
- **발표자**: 조재현

### 리뷰 1
- **리뷰어**: 박민경

#### 요약

RAG는 외부 지식이나 툴을 활용해 Context로 활용한다. 또한 LLM의 hallucination을 방지하고 LLM응답에 대한 신뢰도를 높일 수 있는 실용적인 방법이며 널리 사용되고 있다. 하지만 Context 없이 사전 지식만으로 충분히 답변할 수 있는 경우 이런 Context는 오히려 방해가 되기도 한다. 또한 RAG는 k의 문서를 검색해 입력으로 함께 사용하게 되는 데 k개의 문서 중 크게 관련 없는 문서가 있거나 질문의 복잡도에 비해 양이 많으면 문서가 오히려 noise를 증가시켜버린다. 이는 LLM이 retreived context를 제대로 활용하지 못하게 되는 요인이 되기도 하며, LLM은 주로 검색된 문서를 붙여 답변을 하도록 학습되지 않기도 하다.
이 문제를 해결하기 위해 세미나의 논문은 LLM내부에 Self-reflection 능력을 부여해 모델 스스로 retrieval이 필요한지, 가장 유용한 결과는 무엇인지 반영한다. Self-RAG는 Generator + Retriever + Critic의 iteration 기반의 아키텍처를 가지고 있다. 모든 구성요소는 retrieve, is_relevant, is_supported, is_useful 시그널 토큰 기반으로 매 step self-reflection을 한다. 또한 기존 retrieve는 context를 활용하는 데 최적화 되어 있지 않기 때문에 논문에서는 reflection token 데이터를 augment하여 결과를 잘 활용할 수 있도록 Generator와 Critic을 학습한다.

#### 후기

RAG는 현재 LLM 기반 어플리케이션에서 가장 널리 사용되는 기법 중 하나이다. 실제 활용 과정에서는 retrieved context가 오히려 답변 생성을 방해하거나 불필요한 정보를 포함해 성능을 저해해버릴 수 있다. 이 세미나 발표에서는 이러한 한계를 실용적이고 직관적인 방식으로 해결하려는 접근법을 소개하고 있다. 비록 단순한 retrieval 방식에 비해 연산량이나 응답 latency는 더 발생하지만, 불필요한 정보를 배제하고 compact한 context만으로 정제된 입력을 구성함으로써 전체적인 성능을 끌어올릴 수 있다는 점이 인상적이다.

---

<br>

### 주제 2:
- **발표자**: 

### 리뷰 1
- **리뷰어**: 
(내용)

---