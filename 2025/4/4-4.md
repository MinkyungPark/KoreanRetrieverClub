# 📚 4 - 4 주차

### 주제 1 : Multi-turn Retrieval
- **발표자**: 박민경

### 리뷰 1
- **리뷰어**: 조재현

### 요약
```
Single-turn retrieval이 아닌, Multi-turn retrieval 상황에서의 challenges에 대해 논의하고, 이를 극복하기 위한 기법들을 소개하였다.
Context Overflow -> summary, chunking, and priority context building등의 기법이 존재.
Context Overflow 관련 works: Lost in middle, sufficient context, and COCOM
Retieval Model 관련 works: Lexical retrieval, Dense retrieval, and Sparse retrieval.
Human-like Retrieving: Agentic RAG
```

### 후기
```
연구실 단위에서 RAG는 잘 사용하지 않지만, 회사 단위로는 꽤 중요한 분야인 것 같다.
single-turn retrieval이 아닌 상황 자체를 별로 생각을 안 해봤는데, multi-turn 상황에서는 어떤 것이 문제가 되는 지 이해하게 되었고, 간단한 solutions을 알게 되어 재밌었다.
```

---

### 리뷰 2
- **리뷰어**: 장재후
(내용)

---

<br>

### 주제 2: SCALING LLM TEST-TIME COMPUTE OPTIMALLY CAN BE MORE EFFECTIVE THAN SCALING PARAMETERS FOR REASONING
- **발표자**: 조재현

### 리뷰 1
- **리뷰어**: 박민경

### 요약
```
Test-time budget을 이용하여 LLM 답변 성능의 품질을 얼마나 효율적으로 향상시킬 수 있는지에 대한 주제
test-time시 성능 향상을 위해서 두 가지 접근 법을 취함
PRM(Process Reward Model)을 활용한 Search 기법 - Beam-search, Best-of-N weighted, Lookahead search
Sequential revision를 통한 반복적 답변 수정(ex. Deepseek)
쉬운 문제에서는 revision이 효과적이며 어려운 문제에서는 search 기법이 유리하다
inference budget과 문제 난이도를 안다면 이에 따라 최적의 전략을 사전에 선택할 수 있음을 시사한다.
```

### 후기
```
또한, 최근 LLM을 활용한 Agentic system이 널리 퍼지고 있는 만큼,
추론 시간에 추가 연산을 허용하는 방식과 이를 최적화하는 전략이 더욱 중요한 연구 주제가 될 것이라는 것에도 크게 공감할 수 있었다.
제한된 연산 자원 환경이나 비용 최적화가 중요한 실서비스 환경에서는 이러한 test-time compute 최적화 기법이 LLM 기반 시스템을 설계할 때 핵심적인 고려사항이 될 것 같다.
실제 문제 난이도 예측 및 PRM 학습에 대한 과제가 남아있지만, budge-aware inference 전략이 정교해질 수록 효율적으로 LLM 활용이 가능해질 것이라고 기대된다.
```

---

### 리뷰 2
- **리뷰어**: 장재후
(내용)

---
