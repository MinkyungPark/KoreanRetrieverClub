# 📚 4 - 4 주차

### 주제 1 : Multi-turn Retrieval
- **발표자**: 박민경

### 리뷰 1
- **리뷰어**: 조재현

### 요약
```
Single-turn retrieval이 아닌, Multi-turn retrieval 상황에서의 challenges에 대해 논의하고, 이를 극복하기 위한 기법들을 소개하였다.
Context Overflow -> summary, chunking, and priority context building등의 기법이 존재.
Context Overflow 관련 works: Lost in middle, sufficient context, and COCOM
Retieval Model 관련 works: Lexical retrieval, Dense retrieval, and Sparse retrieval.
Human-like Retrieving: Agentic RAG
```

### 후기
```
연구실 단위에서 RAG는 잘 사용하지 않지만, 회사 단위로는 꽤 중요한 분야인 것 같다.
single-turn retrieval이 아닌 상황 자체를 별로 생각을 안 해봤는데, multi-turn 상황에서는 어떤 것이 문제가 되는 지 이해하게 되었고, 간단한 solutions을 알게 되어 재밌었다.
```

---

### 리뷰 2
- **리뷰어**: 장재후

### 요약
```
non-standalone query가 주어졌을때 multi-turn retrieval 문제에 어떻게 접근 할것이냐에 대해 설명함.
크게 context overflow 방지를 위한 기법, retrieval model 설계 방식, agentic RAG + 검색 시스템 방식들을 활용해서 문제를 풀고 있음 
contxtual query rewriting에도 명시적 재작성, 임베딩으로 문맥을 표현, 사용자 선호도에 맞춘 작성 등 다양한 방법이 있었음.
```

### 후기
```
multi turn retrival에서 사용하는 기법들을 알 수 있어서 좋았습니다.
좀 더 좋은 결과를 도출할 수 있도록 , DSPy 같은 프레임워크를 참고해서 사내에서 사용하는 프롬프트의 품질을 더 높이거나 LLM을 효율적으로 사용할 수 있는 방안을 고안해보는 것도 좋을 것 같습니다.
```
---

<br>

### 주제 2: SCALING LLM TEST-TIME COMPUTE OPTIMALLY CAN BE MORE EFFECTIVE THAN SCALING PARAMETERS FOR REASONING
- **발표자**: 조재현

### 리뷰 1
- **리뷰어**: 박민경

### 요약
```
Test-time budget을 이용하여 LLM 답변 성능의 품질을 얼마나 효율적으로 향상시킬 수 있는지에 대한 주제
test-time시 성능 향상을 위해서 두 가지 접근 법을 취함
PRM(Process Reward Model)을 활용한 Search 기법 - Beam-search, Best-of-N weighted, Lookahead search
Sequential revision를 통한 반복적 답변 수정(ex. Deepseek)
쉬운 문제에서는 revision이 효과적이며 어려운 문제에서는 search 기법이 유리하다
inference budget과 문제 난이도를 안다면 이에 따라 최적의 전략을 사전에 선택할 수 있음을 시사한다.
```

### 후기
```
또한, 최근 LLM을 활용한 Agentic system이 널리 퍼지고 있는 만큼,
추론 시간에 추가 연산을 허용하는 방식과 이를 최적화하는 전략이 더욱 중요한 연구 주제가 될 것이라는 것에도 크게 공감할 수 있었다.
제한된 연산 자원 환경이나 비용 최적화가 중요한 실서비스 환경에서는 이러한 test-time compute 최적화 기법이 LLM 기반 시스템을 설계할 때 핵심적인 고려사항이 될 것 같다.
실제 문제 난이도 예측 및 PRM 학습에 대한 과제가 남아있지만, budge-aware inference 전략이 정교해질 수록 효율적으로 LLM 활용이 가능해질 것이라고 기대된다.
```

---

### 리뷰 2
- **리뷰어**: 장재후

### 요약
```
모델의 크기를 키우는 것보다, 테스트 시점에서의 연산 자원을 프롬프트의 난이도에 따라 적절히 배분하여 활용하는 것이 제한된 연산량을 가진 상황에 성능을 더 올릴 수 있다는 것을 보여준 논문이었음.
이를 위해 LLM 추론 시 고정된 연산 자원 내에서 문제 난이도에 따라 어떤 방법론이 효과적인지 검증하였음.
추론시 비교한 방법들에는 여러 개의 답변을 생성한 후, 각 답변의 중간 추론 과정을 PRM 모델을 기반으로 평가하여 가장 높은 점수를 받은 답변을 선택하는 검색 기법들과 초기 답변을 계속 수정해나가는 수정 기법을 사용했음.
그 결과,
1. FLOPs가 동일할 경우, 작은 모델에 compute-optimal 전략을 적용하는 것이 단순히 큰 모델을 사용하는 것보다 더 높은 성능을 보였음.
2. 쉬운 문제에서는 답변을 반복적으로 수정하는 방식이 효과적이며, 어려운 문제에서는 검색 기법이 더 효과적이었음.
```

### 후기
```
각 task별 훈련된 PRM 모델이 달라짐에 따라 최적화 전략이 달라질수도 있을 것 같다고 생각하면서 재미있게 들었습니다.
모델 거대화보다 파라미터가 적더라도 추론 기법을 적절히 선택하면 한정된 연산량 내에서 더 좋은 성능을 낼 수 있다는 인사이트는 NLP 뿐 만 아니라 타 도메인에서도 적용이 가능하다고 생각이 들어 흥미로웠습니다.
```
---

